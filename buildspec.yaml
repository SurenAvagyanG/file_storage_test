version: 0.2

phases:
  pre_build:
    commands:
      #- echo Installing app dependencies...
      #- curl -LO https://dl.k8s.io/release/v1.27.2/bin/linux/amd64/kubectl
      #- chmod +x ./kubectl
      #- mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
      #- echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
      #- source ~/.bashrc
      - echo 'Check kubectl version'
      - kubectl version --short --client
      - aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 905418328607.dkr.ecr.us-east-1.amazonaws.com
  build:
    commands:
#      - IMAGE_TAG=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7)
#      - docker build -t file_storage .
#      - docker tag file_storage:latest 905418328607.dkr.ecr.us-east-1.amazonaws.com/file_storage:$IMAGE_TAG # Tag with dynamic tag
#      - docker tag file_storage:latest 905418328607.dkr.ecr.us-east-1.amazonaws.com/file_storage:latest
  post_build:
    commands:
      - kubectl get configmap aws-auth -o yaml -n kube-system
      - export ACCOUNT_ID=905418328607
      - ROLE="    - rolearn: arn:aws:iam::$ACCOUNT_ID:role/CodeBuildEKSRole\n      username: build\n      groups:\n        - system:masters"
      - kubectl get -n kube-system configmap/aws-auth -o yaml | awk "/mapRoles: \|/{print;print \"$ROLE\";next}1" > /tmp/auth-patch.yml
      - kubectl patch configmap/aws-auth -n kube-system --patch "$(cat /tmp/auth-patch.yml)"
      #- aws eks update-kubeconfig --name development-cluster --region us-east-1
      #- kubectl config get-contexts
      #- kubectl get configmap aws-auth -o yaml -n kube-system
      - kubectl set image deployment/file-storage file-storage=905418328607.dkr.ecr.us-east-1.amazonaws.com/file_storage:latest
